# Stakeholder-Centered Explainability for Code Generation Models  


This repository contains the **supplementary materials and research artifacts** for the paper:

> **Stakeholder-Centered Explainability for Code Generation Models**  
> *(under review)*



## Abstract

The growing adoption of AI models (including Large Language Models) for code generation in everyday software development has intensified concerns around their transparency and the need for robust explainability methods to foster trust in these systems. Despite a growing body of explainability techniques, little is known about how well these methods serve the distinct goals of two key stakeholder groups: model users (e.g., developers) and model engineers. In this work, we present the first systematic mapping between existing explainability approaches for code generation and the practical questions and concerns of these stakeholders. We gather stakeholder requirements using an LLM-assisted elicitation method. By aligning our gathered requirements and questions with current eXplainable AI (XAI) techniques, we uncover critical gaps in existing explainability support. Our findings lay the groundwork for a more user-centered design of explainability tools in code generation.


### Supplementary Materials and Research Artifacts
The artifacts in this repository support the **systematic literature review (SLR)**, **LLM-assisted requirements elicitation**, **stakeholder validation survey**, and **gap analysis** presented in the paper.  
They are provided to enhance **transparency, reproducibility, and reuse**.

---

## üìÇ Repository Structure and Contents

### üîç Systematic Literature Review (SLR)

- **`slr search/SLR search strings.pdf`**  
  Contains the complete search queries used for the systematic literature review, including the use of wildcard operators (e.g., `explain*`, `interpret*`) to ensure comprehensive coverage.

- **`data extraction/Papers Data Extraction Template and Results.xlsx`**  
  An Excel workbook containing:
  - The data extraction template used in the review
  - Extracted data for the ten selected primary studies
  
---

### ü§ñ LLM-Assisted Requirements Elicitation

- **`prompts and responses/prompts and responses 1 and 2.pdf`**  
  Includes the prompts along with responses generated by the ChatGPT web interface (GPT-4‚Äìclass model) to elicit explainability requirements and questions for:
  - Code generation model users
  - Code generation model engineers

These prompts were used to generate initial requirement sets that were later validated in our user survey.

- **`prompts and responses/prompts 1.0 2.0 3.0 4.0.txt`**  
  Includes the prompts 1.0 and 2.0 for model users and model engineer requirements respectively. Includes the prompt 3.0 for customizing the XAI question bank. Includes the prompt 3.0 for extending the XAI4CodeGen question bank.


---

### ‚ùì Explainability Question Banks

- **`question-banks/CustomizedXAI4CodeGen Question Bank.xlsx`** 
  The question bank generated using prompt 3.0

- **`question-banks/ExtendedXAI4CodeGen Question Bank.xlsx`** 
  The question bank generated by using prompt 4.0

- **`question-banks/XAIQB_OriginalQuestions_SideBySIde_WithCustomizedQuestions.pdf`**  
  A side-by-side comparison of:
  - An existing explainability question bank for general AI models
  - The customized question bank developed in this study from Prompt 3.0

  This document highlights how stakeholder-driven questions extend beyond existing formulations.

---

### üìä Stakeholder Survey

- **`survey/survey 1.pdf`**  
- **`survey/survey 2.pdf`** 
  The survey instruments used to validate the relevance of:
  - Model user requirements (Survey 1)
  - Model engineer requirements (Survey 1)
  - Extended XAI4CodeGen Question Bank (Survey 1)
  - Customized explainability questions for XAI4CodeGen (Survey 2)

Survey responses validated the alignment of ChatGPT-elicited explainability requirements for code generation models with actual model users and model engineers.

Survey results can be found
- **`survey/Survey 1 results.xlsx`**  
- **`survey/Survey 2 results.xlsx`** 

---

### üîÅ Artifact‚ÄìPaper Traceability

- **`artifact-mapping.md`**  
  Provides a mapping between the paper sections, tables, and results and the corresponding artifacts in this repository.

---

## ‚ö†Ô∏è Reproducibility and Tooling Notes

- Requirements elicitation was conducted using the **ChatGPT web interface (OpenAI)**.
- At the time of use, ChatGPT was powered by a **GPT-4‚Äìclass model**.
- The exact model version and minor revisions are not disclosed by OpenAI.
- Due to the non-deterministic nature of LLMs, regenerated outputs may vary slightly.

These factors are discussed as part of the **threats to validity** in the paper.

---

## üìú License

This repository is released under the **MIT** license.  
You are free to reuse the materials with appropriate attribution.

---

## üì£ How to Cite

If you use these artifacts, please cite the associated paper.  
A `CITATION.cff` file is provided to support easy citation via GitHub.

---

## ü§ù Contact

For questions or clarifications regarding the artifacts, please contact the authors via the email provided in the paper.
