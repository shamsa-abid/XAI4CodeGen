# XAI4CodeGen
This repo will contain our data and results for our research on "Explaining Code Generation AI Models: Are We Meeting Stakeholder Needs?"



The growing adoption of AI models (including Large Language Models) for code generation in everyday software development has intensified concerns around their transparency and the need for robust explainability methods to foster trust in these systems. Despite a growing body of explainability techniques, little is known about how well these methods serve the distinct goals of two key stakeholder groups: model users (e.g., developers) and model engineers. In this work, we present the first systematic mapping between existing explainability approaches for code generation and the practical questions and concerns of these takeholders.We gather stakeholder requirements using an LLM-assisted elicitation method. By aligning our gathered requirements and questions with current eXplainable AI (XAI) techniques, we uncover critical gaps in existing explainability support. Our findings lay the groundwork for a more user-centered design of explainability tools in code generation.
